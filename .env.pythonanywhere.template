# ======================================
# PYTHONANYWHERE .env TEMPLATE
# ======================================
# Copy file này thành .env và sửa các giá trị

# === Django Core Settings ===
# Generate SECRET_KEY bằng:
# python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
SECRET_KEY=your-secret-key-here-change-this-immediately

# Debug mode (PHẢI False trong production!)
DEBUG=False

# Allowed hosts - Thay 'yourusername' bằng username PythonAnywhere của bạn
ALLOWED_HOSTS=yourusername.pythonanywhere.com

# Database name (mặc định là db.sqlite3)
DB_NAME=db.sqlite3

# === Model Loading Config (QUAN TRỌNG!) ===
# PythonAnywhere: Lazy loading để tiết kiệm RAM lúc startup
PRELOAD_MODEL=false

# Grad-CAM: BẬT vì model chỉ 95MB, peak ~400MB < 512MB
ENABLE_GRADCAM=true

# Server mode detection
DJANGO_SERVER_MODE=true

# === TensorFlow Optimizations ===
# Giảm log spam
TF_CPP_MIN_LOG_LEVEL=3

# Tắt oneDNN để tiết kiệm RAM
TF_ENABLE_ONEDNN_OPTS=0

# Single thread để tránh overhead
OMP_NUM_THREADS=1
OPENBLAS_NUM_THREADS=1
MKL_NUM_THREADS=1

# === Gemini API (Optional) ===
# Nếu dùng chatbot với Gemini API
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp

# ======================================
# NOTES
# ======================================
# Model size: 95MB
# Expected memory:
#   - Idle: ~150-200MB
#   - After model load: ~280-310MB  
#   - Peak (inference + Grad-CAM): ~400MB < 512MB ✅
#
# Performance:
#   - Request đầu: ~65-70s (load model)
#   - Request sau: ~8-12s (có Grad-CAM)
#   - Timeout: 300s (dư thừa!)
