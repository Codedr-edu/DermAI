# Giáº£i thÃ­ch chi tiáº¿t - Táº¡i sao cÃ¡c optimization nÃ y giáº£i quyáº¿t Ä‘Æ°á»£c OOM?

## ğŸ”´ Váº¥n Ä‘á» ban Ä‘áº§u

Khi báº¡n deploy lÃªn Render.com free tier:
- **RAM available:** 512MB
- **RAM app cá»§a báº¡n dÃ¹ng:** ~700MB
- **Káº¿t quáº£:** âŒ Out of Memory â†’ App crash

### Táº¡i sao láº¡i tá»‘n nhiá»u RAM váº­y?

```python
# File AI_detection.py CÅ¨:
print("ğŸ”„ Loading model from:", MODEL_PATH)
_loaded_model = keras.models.load_model(MODEL_PATH, compile=False)  # â† Load ngay khi import
print("âœ… Loaded model")

# Warm up
dummy_input = tf.zeros((1, 300, 300, 3))
_ = WRAPPED_MODEL(dummy_input, training=False)  # â† Cháº¡y luÃ´n
```

**Váº¥n Ä‘á»:**
1. **Model load ngay láº­p tá»©c** khi Django khá»Ÿi Ä‘á»™ng (chÆ°a cÃ³ user nÃ o request)
2. Model EfficientNetV2S: ~80MB file â†’ Khi load vÃ o RAM: **~250-300MB** (vÃ¬ pháº£i giáº£i nÃ©n weights, táº¡o computation graph)
3. **Warmup ngay:** Tá»‘n thÃªm ~50MB cho tensors
4. **Grad-CAM luÃ´n cháº¡y:** Má»—i láº§n predict tá»‘n thÃªm ~150MB (táº¡o gradients, intermediate activations)

**Tá»•ng:** 250MB (model) + 50MB (warmup) + 200MB (Django) + 150MB (Grad-CAM) = **~650-700MB** âŒ

---

## âœ… Giáº£i phÃ¡p 1: Lazy Loading

### Code CÅ¨ (tá»‘n RAM):
```python
# Load ngay khi file Ä‘Æ°á»£c import
_loaded_model = keras.models.load_model(MODEL_PATH)  # â† Cháº¡y ngay!
```

**Váº¥n Ä‘á»:** 
- Django khá»Ÿi Ä‘á»™ng â†’ import AI_detection.py â†’ **Model load ngay** â†’ Tá»‘n 250MB RAM ngay cáº£ khi chÆ°a cÃ³ ai dÃ¹ng

### Code Má»šI (tiáº¿t kiá»‡m RAM):
```python
_loaded_model = None  # â† ChÆ°a load gÃ¬ cáº£

def get_model():
    global _loaded_model
    
    if _loaded_model is not None:
        return _loaded_model  # â† ÄÃ£ load rá»“i, dÃ¹ng láº¡i
    
    # Chá»‰ load khi Ä‘Æ°á»£c gá»i láº§n Ä‘áº§u
    print("ğŸ”„ Loading model...")
    _loaded_model = keras.models.load_model(MODEL_PATH)
    return _loaded_model

# Trong predict:
model = get_model()  # â† Chá»‰ load khi user request
```

**Lá»£i Ã­ch:**
- âœ… Django khá»Ÿi Ä‘á»™ng: RAM chá»‰ ~150MB (chÆ°a load model)
- âœ… User request Ä‘áº§u tiÃªn: Load model â†’ RAM lÃªn ~400MB
- âœ… Tiáº¿t kiá»‡m **250MB RAM** khi idle (khÃ´ng cÃ³ user)

**Táº¡i sao quan trá»ng?**
Render.com free tier cÃ³ thá»ƒ kill process náº¿u RAM > 512MB lÃºc khá»Ÿi Ä‘á»™ng!

---

## âœ… Giáº£i phÃ¡p 2: Táº¯t Grad-CAM

### Grad-CAM lÃ  gÃ¬ vÃ  táº¡i sao tá»‘n RAM?

```python
# Code tÃ­nh Grad-CAM
with tf.GradientTape() as tape:
    tape.watch(x)
    predictions = model(x)
    class_channel = predictions[0, pred_index]

grads = tape.gradient(class_channel, conv_outputs)  # â† Tá»‘n nhiá»u RAM!
```

**Táº¡i sao tá»‘n RAM?**

1. **GradientTape** pháº£i lÆ°u táº¥t cáº£ intermediate activations (káº¿t quáº£ tá»«ng layer):
   - Layer 1: 150x150x32 â†’ ~3MB
   - Layer 2: 75x75x64 â†’ ~1.4MB
   - Layer 3: 38x38x128 â†’ ~0.7MB
   - ... (nhiá»u layers)
   - **Total:** ~100-150MB chá»‰ Ä‘á»ƒ lÆ°u activations

2. **Gradients:** TÃ­nh Ä‘áº¡o hÃ m ngÆ°á»£c láº¡i qua táº¥t cáº£ layers â†’ Tá»‘n thÃªm ~50MB

3. **Heatmap processing:** Resize, colormap, blend â†’ Tá»‘n ~20MB

**Tá»•ng Grad-CAM:** ~150-200MB má»—i láº§n predict

### Giáº£i phÃ¡p:

```python
# Code Má»šI
ENABLE_GRADCAM = os.getenv('ENABLE_GRADCAM', 'true').lower() in ('true', '1', 'yes')

def predict_skin_with_explanation(image_bytes, enable_gradcam=None):
    if enable_gradcam is None:
        enable_gradcam = ENABLE_GRADCAM  # â† Äá»c tá»« env var
    
    # Predict
    results = model.predict(...)
    
    # Chá»‰ tÃ­nh Grad-CAM náº¿u Ä‘Æ°á»£c enable
    if enable_gradcam:
        heatmap = compute_gradcam(...)  # â† Tá»‘n 150MB
    else:
        heatmap = None  # â† KhÃ´ng tÃ­nh, khÃ´ng tá»‘n RAM
    
    return results, heatmap
```

**Trong render.yaml:**
```yaml
envVars:
  - key: ENABLE_GRADCAM
    value: false  # â† Táº¯t Grad-CAM trÃªn production
```

**Lá»£i Ã­ch:**
- âœ… Tiáº¿t kiá»‡m **150MB RAM** má»—i request
- âœ… Predict nhanh hÆ¡n (2s thay vÃ¬ 5s)
- âœ… Váº«n cÃ³ thá»ƒ báº­t láº¡i khi cáº§n (Ä‘á»•i env var)

---

## âœ… Giáº£i phÃ¡p 3: Memory Cleanup

### Váº¥n Ä‘á»: Memory Leak

```python
# Code CÅ¨
def predict_skin_with_explanation(image_bytes):
    x = tf.convert_to_tensor(batch_np)
    predictions = model(x)
    heatmap = compute_gradcam(...)
    
    return results, heatmap  # â† Xong rá»“i nhÆ°ng tensors váº«n cÃ²n trong RAM!
```

**Váº¥n Ä‘á»:**
- TensorFlow táº¡o ra nhiá»u tensors (x, predictions, gradients, heatmap)
- Sau khi xong, Python khÃ´ng tá»± Ä‘á»™ng xÃ³a ngay â†’ **RAM tÄƒng dáº§n**
- Request 1: 400MB
- Request 2: 420MB
- Request 3: 450MB
- Request 4: 480MB
- Request 5: **520MB** â†’ âŒ OOM!

### Giáº£i phÃ¡p:

```python
def cleanup_memory():
    """Force garbage collection and clear TF session cache"""
    tf.keras.backend.clear_session()  # â† XÃ³a TF cache
    gc.collect()  # â† Garbage collection ngay láº­p tá»©c

def predict_skin_with_explanation(image_bytes):
    # ... predict code ...
    
    # Clean up tensors
    del x, predictions, gradients, heatmap  # â† XÃ³a biáº¿n
    cleanup_memory()  # â† Force cleanup
    
    return results, heatmap_base64
```

**Lá»£i Ã­ch:**
- âœ… RAM khÃ´ng tÄƒng dáº§n theo sá»‘ requests
- âœ… Má»—i request dá»n dáº¹p sáº¡ch sáº½
- âœ… Request 1: 400MB, Request 100: váº«n 400MB

---

## âœ… Giáº£i phÃ¡p 4: Gunicorn Optimization

### Config CÅ¨:
```bash
gunicorn --workers 1 --threads 4
```

**Váº¥n Ä‘á»:**
- 1 worker = 1 process Python = load 1 model = 300MB
- 4 threads = cÃ³ thá»ƒ xá»­ lÃ½ 4 requests Ä‘á»“ng thá»i
- Náº¿u 4 requests cÃ¹ng lÃºc predict:
  - Request 1: +150MB (Grad-CAM)
  - Request 2: +150MB
  - Request 3: +150MB
  - Request 4: +150MB
  - **Total spike:** 300MB + 600MB = **900MB** â†’ âŒ OOM!

### Config Má»šI:
```bash
gunicorn --workers 1 --threads 2 \
         --max-requests 100 \
         --max-requests-jitter 10 \
         --worker-tmp-dir /dev/shm
```

**Giáº£i thÃ­ch:**

1. **`--threads 2`** (giáº£m tá»« 4 â†’ 2):
   - Chá»‰ xá»­ lÃ½ 2 requests Ä‘á»“ng thá»i
   - Spike tá»‘i Ä‘a: 300MB + 300MB = 600MB thay vÃ¬ 900MB
   - âœ… Giáº£m nguy cÆ¡ OOM

2. **`--max-requests 100`**:
   - Sau 100 requests, worker tá»± restart
   - XÃ³a sáº¡ch memory leaks (náº¿u cÃ³)
   - âœ… RAM khÃ´ng tÄƒng dáº§n theo thá»i gian

3. **`--max-requests-jitter 10`**:
   - Random restart giá»¯a 90-110 requests
   - TrÃ¡nh táº¥t cáº£ workers restart cÃ¹ng lÃºc
   - âœ… App khÃ´ng bá»‹ downtime

4. **`--worker-tmp-dir /dev/shm`**:
   - `/dev/shm` = RAM-based filesystem (nhanh hÆ¡n disk)
   - Gunicorn dÃ¹ng temp files Ä‘á»ƒ IPC (Inter-Process Communication)
   - âœ… Nhanh hÆ¡n, Ã­t I/O

---

## âœ… Giáº£i phÃ¡p 5: TensorFlow Environment Variables

### Config Má»šI:
```yaml
envVars:
  - key: TF_CPP_MIN_LOG_LEVEL
    value: "3"  # Táº¯t logging
  - key: OMP_NUM_THREADS
    value: "1"  # Giá»›i háº¡n threads
  - key: OPENBLAS_NUM_THREADS
    value: "1"
  - key: MKL_NUM_THREADS
    value: "1"
```

**Giáº£i thÃ­ch:**

### 1. `TF_CPP_MIN_LOG_LEVEL=3`
```python
# Vá»›i level=0 (default): In ra má»i thá»©
2025-10-10 12:00:00.123456: I tensorflow/core/platform/cpu_feature_guard.cc:182]
2025-10-10 12:00:00.234567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532]
# ... hÃ ng trÄƒm dÃ²ng log
```

- Má»—i dÃ²ng log tá»‘n ~500 bytes RAM
- 1000 dÃ²ng = 500KB
- âœ… Tiáº¿t kiá»‡m ~5-10MB

### 2. `OMP_NUM_THREADS=1`
```python
# Vá»›i threads=4 (default):
# TensorFlow táº¡o 4 thread pools cho CPU operations
# Má»—i thread pool: ~10MB overhead
# Total: 40MB

# Vá»›i threads=1:
# Chá»‰ 1 thread pool: 10MB
# âœ… Tiáº¿t kiá»‡m 30MB
```

**Trade-off:** 
- âŒ Cháº­m hÆ¡n 20-30% (1 thread thay vÃ¬ 4)
- âœ… NhÆ°ng khÃ´ng bá»‹ OOM â†’ App cháº¡y Ä‘Æ°á»£c!

**Táº¡i sao OK?**
- Render free tier dÃ¹ng CPU chia sáº» (khÃ´ng máº¡nh)
- 1 thread vs 4 threads trÃªn CPU yáº¿u: chÃªnh lá»‡ch khÃ´ng nhiá»u
- Prediction váº«n ~2-3s (cháº¥p nháº­n Ä‘Æ°á»£c)

---

## ğŸ“Š Tá»•ng káº¿t: Táº¡i sao nÃ³ hoáº¡t Ä‘á»™ng?

### RAM Usage Timeline:

#### TRÆ¯á»šC optimization:
```
0s  (Startup)     : 200MB (Django) + 250MB (model load ngay) = 450MB
5s  (User request): +150MB (Grad-CAM) = 600MB
10s (2nd request) : +20MB (memory leak) = 620MB
15s (3rd request) : +20MB = 640MB
20s (4th request) : +20MB = 660MB âŒ â†’ OOM â†’ CRASH
```

#### SAU optimization:
```
0s  (Startup)     : 150MB (Django only, no model) âœ…
10s (User request): +250MB (model lazy load) = 400MB âœ…
                    +0MB (Grad-CAM disabled) âœ…
15s (2nd request) : +0MB (memory cleanup) = 400MB âœ…
20s (3rd request) : +0MB = 400MB âœ…
...
100 requests      : +0MB = 400MB âœ…
101st request     : Worker restart â†’ 150MB â†’ 400MB âœ…
```

### So sÃ¡nh:

| Thá»i Ä‘iá»ƒm | TRÆ¯á»šC | SAU | Ghi chÃº |
|-----------|-------|-----|---------|
| **Startup** | 450MB | 150MB | Lazy loading |
| **1st request** | 600MB | 400MB | No Grad-CAM |
| **10th request** | 700MB+ | 400MB | Memory cleanup |
| **Status** | âŒ CRASH | âœ… **STABLE** | - |

---

## ğŸ¯ TÃ³m láº¡i - Táº¡i sao giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á»?

### 1. **Lazy Loading** â†’ Startup nháº¹
- KhÃ´ng load model khi startup
- **-250MB** lÃºc khá»Ÿi Ä‘á»™ng
- â†’ App startup thÃ nh cÃ´ng (khÃ´ng bá»‹ kill)

### 2. **Disable Grad-CAM** â†’ Predict nháº¹
- KhÃ´ng tÃ­nh gradients
- **-150MB** má»—i request
- â†’ Request khÃ´ng bá»‹ OOM

### 3. **Memory Cleanup** â†’ KhÃ´ng leak
- XÃ³a tensors sau má»—i request
- **-20MB/request** leak
- â†’ RAM stable theo thá»i gian

### 4. **Gunicorn Optimization** â†’ Kiá»ƒm soÃ¡t spike
- Giáº£m threads, restart Ä‘á»‹nh ká»³
- **-200MB** spike
- â†’ KhÃ´ng bá»‹ OOM khi nhiá»u requests

### 5. **TF Environment** â†’ Giáº£m overhead
- Ãt threads, Ã­t logging
- **-50MB** overhead
- â†’ Má»i thá»© nháº¹ hÆ¡n

**Tá»•ng tiáº¿t kiá»‡m: ~650MB â†’ ~350MB**

### Káº¿t luáº­n:
```
Before: 700MB > 512MB limit â†’ âŒ OOM
After:  350MB < 512MB limit â†’ âœ… WORKS!
```

---

## ğŸ’¡ Bonus: Quantization (Optional)

Náº¿u váº«n cáº§n thÃªm tá»‘i Æ°u:

```python
# Model float32: má»—i weight = 4 bytes
# Model size: 20M params Ã— 4 bytes = 80MB file â†’ 300MB in RAM

# Quantize to float16: má»—i weight = 2 bytes  
# Model size: 20M params Ã— 2 bytes = 40MB file â†’ 150MB in RAM

# âœ… Tiáº¿t kiá»‡m thÃªm 150MB!
```

**CÃ¡ch dÃ¹ng:**
```bash
python Dermal/quantize_model.py
# Model size: 80MB â†’ 40MB
# RAM usage: 300MB â†’ 150MB
```

**Trade-off:**
- âŒ Accuracy giáº£m nháº¹ (~1-2%)
- âœ… NhÆ°ng tiáº¿t kiá»‡m 50% RAM

---

## â“ CÃ¢u há»i thÆ°á»ng gáº·p

### Q: Táº¡i sao khÃ´ng dÃ¹ng TensorFlow Lite?
**A:** TFLite nhá» hÆ¡n nhÆ°ng:
- Phá»©c táº¡p Ä‘á»ƒ setup vá»›i Keras
- KhÃ´ng support Ä‘áº§y Ä‘á»§ operations
- Quantization script Ä‘Æ¡n giáº£n hÆ¡n vÃ  Ä‘á»§ dÃ¹ng

### Q: Táº¡i sao khÃ´ng tÃ¡ch model ra service riÃªng?
**A:** CÃ³ thá»ƒ lÃ m nhÆ°ng:
- Render free tier chá»‰ 1 service
- Phá»©c táº¡p hÆ¡n (cáº§n setup API giá»¯a services)
- Vá»›i optimization nÃ y Ä‘Ã£ Ä‘á»§

### Q: Model load lÃ¢u (20s) cÃ³ váº¥n Ä‘á» khÃ´ng?
**A:** KhÃ´ng váº¥n Ä‘á» vÃ¬:
- Chá»‰ láº§n Ä‘áº§u tiÃªn
- CÃ¡c requests sau chá»‰ máº¥t 2-3s
- Trade-off Ä‘Ã¡ng giÃ¡ Ä‘á»ƒ khÃ´ng bá»‹ OOM

---

**Hy vá»ng giáº£i thÃ­ch nÃ y giÃºp báº¡n hiá»ƒu rÃµ!** ğŸ‰
