# âš–ï¸ SO SÃNH: RENDER vs PYTHONANYWHERE

## ğŸ“Š Báº¢NG SO SÃNH NHANH

| Feature | Render Free | PythonAnywhere Free | Chiáº¿n tháº¯ng |
|---------|-------------|---------------------|-------------|
| **RAM** | 512MB | 512MB | ğŸ¤ HÃ²a |
| **HTTP Timeout** | 30-60s | 300s (5 phÃºt) | ğŸ† PA |
| **Spin Down** | âœ… Sau 15 phÃºt | âŒ KhÃ´ng (24/7) | ğŸ† PA |
| **Cold Start** | ~50s | KhÃ´ng cÃ³ | ğŸ† PA |
| **Deploy** | Git push auto | Manual upload | ğŸ† Render |
| **SSL** | Free (auto) | Free (auto) | ğŸ¤ HÃ²a |
| **Custom Domain** | Free | Paid ($5+) | ğŸ† Render |
| **Database** | PostgreSQL free | MySQL free | ğŸ¤ HÃ²a |

---

## ğŸ¯ Váº¤N Äá»€ TIMEOUT Vá»šI MODEL Lá»šN

### Render Free (Váº¥n Ä‘á» nghiÃªm trá»ng!)

```
User khÃ´ng truy cáº­p 15 phÃºt
  â†“
App spin down (container shutdown)
  â†“
User truy cáº­p láº¡i
  â†“
Cold start: 50s (boot container)
  â†“
Load Django: 5s
  â†“
Load TensorFlow model: 60s  â† CHáº¬M!
  â†“
Inference: 5s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 120s >>> 60s timeout âŒ REQUEST FAILED!
```

**Giáº£i phÃ¡p cho Render:**
- âœ… **PRE-LOAD model trong apps.py**
- Load model khi Django start (khÃ´ng Ä‘á»£i request)
- Request Ä‘áº§u tiÃªn chá»‰ máº¥t 5s inference

```
Cold start: 50s
  â†“
Load Django + Pre-load model: 65s
  â†“
Server ready âœ…
  â†“
User request â†’ Inference: 5s âœ… SUCCESS!
```

---

### PythonAnywhere Free (KhÃ´ng cÃ³ váº¥n Ä‘á»!)

```
App cháº¡y 24/7 (khÃ´ng spin down)
  â†“
Request Ä‘áº§u tiÃªn
  â†“
Load model: 60s (lazy loading)
  â†“
Inference: 5s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 65s <<< 300s timeout âœ… SUCCESS!
  â†“
Request tiáº¿p theo
  â†“
Model Ä‘Ã£ load â†’ Inference: 5s âœ…
```

**Giáº£i phÃ¡p cho PythonAnywhere:**
- âœ… **LAZY LOADING lÃ  tá»‘t nháº¥t!**
- KHÃ”NG cáº§n pre-load (tá»‘n RAM)
- Timeout 300s quÃ¡ Ä‘á»§
- Tiáº¿t kiá»‡m RAM (~300MB idle)

---

## ğŸ’¾ CHIáº¾N LÆ¯á»¢C RAM

### Render: Pre-loading

**RAM Usage Timeline:**
```
App start: 100MB (Django base)
  â†“ Pre-load model
400MB â†’ 1200MB (model + TensorFlow)
  â†“ LuÃ´n giá»¯ trong RAM
1200MB (constant)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Request Ä‘áº§u tiÃªn nhanh
- âœ… Táº¥t cáº£ requests Ä‘á»u nhanh (~5s)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ RAM cao ngay tá»« Ä‘áº§u
- âŒ CÃ³ thá»ƒ bá»‹ OOM náº¿u model > 400MB

### PythonAnywhere: Lazy Loading

**RAM Usage Timeline:**
```
App start: 100MB (Django idle)
  â†“ Chá» request
300MB (Django + dependencies)
  â†“ Request Ä‘áº§u tiÃªn â†’ Load model
300MB â†’ 1200MB (model loaded)
  â†“ Giá»¯ trong RAM
1200MB (sau khi load)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… RAM tháº¥p lÃºc khá»Ÿi Ä‘á»™ng
- âœ… KhÃ´ng bá»‹ kill khi start
- âœ… Chá»‰ load khi thá»±c sá»± cáº§n

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ Request Ä‘áº§u tiÃªn cháº­m (60s)
- NhÆ°ng OK vÃ¬ timeout 300s!

---

## ğŸ”§ Cáº¤U HÃŒNH CODE

### apps.py (Há»— trá»£ Cáº¢ HAI!)

Code hiá»‡n táº¡i Ä‘Ã£ support cáº£ Render vÃ  PythonAnywhere:

```python
class DermalConfig(AppConfig):
    def ready(self):
        # Kiá»ƒm tra environment variable
        preload = os.getenv('PRELOAD_MODEL', 'true')
        
        # Detect server (Gunicorn OR mod_wsgi)
        is_server = (
            'gunicorn' in sys.argv[0] or      # â† Render
            'mod_wsgi' in sys.modules or       # â† PythonAnywhere
            os.getenv('DJANGO_SERVER_MODE')    # â† Manual config
        )
        
        if preload and is_server:
            model = AI_detection.get_model()  # Pre-load
```

**Flexibility:**
- Control qua environment variable `PRELOAD_MODEL`
- Tá»± Ä‘á»™ng detect platform (Render hoáº·c PA)

---

## âš™ï¸ RECOMMENDED CONFIG

### Cho Render Free:

```bash
# render.yaml hoáº·c Environment Variables
PRELOAD_MODEL=true         # â† Báº®T BUá»˜C Ä‘á»ƒ trÃ¡nh timeout!
ENABLE_GRADCAM=true        # OK náº¿u RAM Ä‘á»§
DJANGO_SERVER_MODE=true
```

**Gunicorn command:**
```bash
gunicorn dermai.wsgi:application \
  --workers 1 \
  --preload-app \           # â† Load trÆ°á»›c khi fork
  --timeout 300
```

**Káº¿t quáº£:**
- Cold start + pre-load: ~65s (diá»…n ra trÆ°á»›c request)
- Request Ä‘áº§u tiÃªn: ~5s âœ…
- Request tiáº¿p theo: ~3-5s âœ…

---

### Cho PythonAnywhere Free:

```bash
# .env file
PRELOAD_MODEL=false        # â† RECOMMENDED Ä‘á»ƒ tiáº¿t kiá»‡m RAM!
ENABLE_GRADCAM=false       # Táº¯t Ä‘á»ƒ tiáº¿t kiá»‡m ~200MB
DJANGO_SERVER_MODE=true
```

**WSGI config:**
```python
# KhÃ´ng cáº§n config gÃ¬ thÃªm
# mod_wsgi tá»± Ä‘á»™ng handle
```

**Káº¿t quáº£:**
- App start: ~5s (khÃ´ng load model)
- Request Ä‘áº§u tiÃªn: ~65s (load model) âš ï¸ CHáº¤P NHáº¬N!
- Request tiáº¿p theo: ~3-5s âœ…

---

## ğŸ¯ DECISION MATRIX

### Khi nÃ o dÃ¹ng Render?

âœ… **DÃ¹ng Render náº¿u:**
- Báº¡n muá»‘n auto-deploy tá»« GitHub
- CÃ³ traffic Ä‘á»u (app khÃ´ng sleep lÃ¢u)
- Cáº§n request Ä‘áº§u tiÃªn nhanh
- Model < 400MB (sau quantization)
- OK vá»›i viá»‡c app sleep khi khÃ´ng dÃ¹ng

âŒ **KHÃ”NG dÃ¹ng Render náº¿u:**
- Model > 1GB vÃ  khÃ´ng thá»ƒ quantize
- RAM 512MB khÃ´ng Ä‘á»§
- Traffic thÆ°a (app sleep nhiá»u â†’ cold start liÃªn tá»¥c)

---

### Khi nÃ o dÃ¹ng PythonAnywhere?

âœ… **DÃ¹ng PythonAnywhere náº¿u:**
- Traffic thÆ°a (Ã­t user)
- Cháº¥p nháº­n request Ä‘áº§u tiÃªn cháº­m (60s)
- Cáº§n uptime 24/7
- Muá»‘n tiáº¿t kiá»‡m RAM
- OK vá»›i manual deployment

âŒ **KHÃ”NG dÃ¹ng PythonAnywhere náº¿u:**
- Cáº§n request Ä‘áº§u tiÃªn nhanh (<10s)
- Cáº§n auto-deploy from Git
- Cáº§n custom domain (free tier khÃ´ng support)

---

## ğŸ’° COST COMPARISON

### Free Tier:

| Feature | Render | PythonAnywhere |
|---------|--------|----------------|
| **Price** | $0 | $0 |
| **RAM** | 512MB | 512MB |
| **Disk** | Ephemeral | 512MB |
| **Bandwidth** | Unlimited | 100k hits/day |
| **Uptime** | Spin down after 15min | 24/7 |

### Paid Tier (náº¿u cáº§n upgrade):

| Feature | Render Starter | PA Hacker |
|---------|----------------|-----------|
| **Price** | $7/month | $5/month |
| **RAM** | 2GB | 1GB |
| **Disk** | Persistent | 1GB |
| **Workers** | Custom | 2 workers |
| **Custom domain** | âœ… Free | âœ… Included |

**Recommendation:** Náº¿u RAM 512MB khÃ´ng Ä‘á»§ â†’ **Upgrade PythonAnywhere ($5)** ráº» hÆ¡n Render ($7)!

---

## ğŸ“‹ CHECKLIST DEPLOY

### Cho Render:

```bash
# 1. Sá»­a render.yaml
startCommand: "gunicorn ... --preload-app"

# 2. Set environment variables
PRELOAD_MODEL=true
DJANGO_SERVER_MODE=true
ENABLE_GRADCAM=true   # hoáº·c false náº¿u RAM khÃ´ng Ä‘á»§

# 3. Deploy
git push origin main

# 4. Monitor logs
render logs

# 5. Test
curl https://your-app.onrender.com/health?verbose=1
```

---

### Cho PythonAnywhere:

```bash
# 1. Upload code
git clone hoáº·c upload ZIP

# 2. Táº¡o .env
PRELOAD_MODEL=false
ENABLE_GRADCAM=false
DJANGO_SERVER_MODE=true

# 3. Install dependencies
pip install --user -r requirements.txt

# 4. Migrations
python manage.py migrate
python manage.py collectstatic

# 5. Config WSGI file
# (theo hÆ°á»›ng dáº«n trong DEPLOYMENT_PYTHONANYWHERE.md)

# 6. Reload web app
# Click "Reload" button trong Web UI

# 7. Test (cháº¥p nháº­n láº§n Ä‘áº§u cháº­m!)
curl https://yourusername.pythonanywhere.com/health?verbose=1
```

---

## ğŸ† Káº¾T LUáº¬N

### TL;DR:

**Render:**
- Váº¥n Ä‘á»: Timeout do spin down
- Giáº£i phÃ¡p: Pre-load model âœ…
- Config: `PRELOAD_MODEL=true`

**PythonAnywhere:**
- Váº¥n Ä‘á»: RAM háº¡n cháº¿
- Giáº£i phÃ¡p: Lazy loading âœ…
- Config: `PRELOAD_MODEL=false`

### Code hiá»‡n táº¡i:

âœ… **ÄÃ£ support Cáº¢ HAI platforms!**
- Detection logic cho cáº£ Gunicorn vÃ  mod_wsgi
- Control qua environment variable
- Graceful fallback náº¿u load fail
- Memory monitoring built-in

### Ready to deploy:

- âœ… Render: Set `PRELOAD_MODEL=true`
- âœ… PythonAnywhere: Set `PRELOAD_MODEL=false`
- âœ… Code tá»± detect platform
- âœ… KhÃ´ng cáº§n sá»­a gÃ¬ thÃªm!

**Deploy ngay!** ğŸš€
