# âš ï¸ THá»°C Táº¾: 512MB LÃ€ HARD LIMIT!

## ğŸš¨ TÃ”I ÄÃƒ SAI!

### âŒ Hiá»ƒu láº§m cá»§a tÃ´i:

```
"Peak 780MB chá»‰ temporary 2-3s â†’ Linux tolerate"
â†’ SAI HOÃ€N TOÃ€N!
```

### âœ… Thá»±c táº¿:

**PythonAnywhere Free: 512MB lÃ  HARD LIMIT**
- Náº¿u process dÃ¹ng > 512MB â†’ **KILL NGAY Láº¬P Tá»¨C!**
- KHÃ”NG cÃ³ "temporary spike" nÃ o Ä‘Æ°á»£c tolerate!
- KHÃ”NG cÃ³ grace period!

**Linux memory overcommit â‰  Ignore RAM limit:**
- Overcommit: Cho phÃ©p ALLOCATE nhiá»u hÆ¡n RAM
- NhÆ°ng khi THá»°C Sá»° DÃ™NG > limit â†’ OOM killer!

---

## ğŸ”¢ TÃNH Láº I THáº¬T Ká»¸

### Scenario 1: Model 400MB (quantized FP16)

```
Django + Python:           ~80 MB
TensorFlow runtime:       ~150 MB  
Model loaded (FP16):      ~400 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IDLE:                     ~630 MB >>> 512 MB âŒ ÄÃƒ QUÃ!
```

**â†’ ChÆ°a lÃ m gÃ¬ Ä‘Ã£ vÆ°á»£t 512MB rá»“i!** âŒ

---

### Scenario 2: Model ~300MB (quantized + optimized)

Giáº£ sá»­ tá»‘i Æ°u cá»±c ká»³ tá»‘t:

```
Django + Python:           ~70 MB
TensorFlow (minimal):     ~120 MB  
Model (aggressive quant): ~300 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IDLE:                     ~490 MB < 512 MB âœ…
```

**BÃ¢y giá» thá»­ inference + Grad-CAM:**

```
Idle:                      490 MB
+ Image preprocessing:     +10 MB = 500 MB
+ Inference buffers:       +30 MB = 530 MB >>> 512 MB âŒ
```

**â†’ ChÆ°a tá»›i Grad-CAM Ä‘Ã£ over rá»“i!** âŒ

---

### Scenario 3: KhÃ´ng cÃ³ Grad-CAM

```
Idle:                      490 MB
+ Image preprocessing:     +10 MB = 500 MB
+ Inference buffers:       +20 MB = 510 MB < 512 MB âœ… (vá»«a khÃ­t!)
```

**â†’ KhÃ´ng Grad-CAM, CHá»ˆ inference, Vá»ªA KHÃT!** âš ï¸

**Káº¿t luáº­n:** Model pháº£i < 300MB Ä‘á»ƒ inference khÃ´ng bá»‹ OOM!

---

## ğŸ’¡ Váº¬Y LÃ€M SAO Äá»‚ CÃ“ GRAD-CAM?

### Option 1: Model Cá»°C Ká»² NHá» (<200MB)

Náº¿u model ~200MB:

```
Django + Python:          ~70 MB
TensorFlow:              ~120 MB  
Model:                   ~200 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IDLE:                    ~390 MB

+ Inference:              +20 MB = 410 MB
+ Grad-CAM computation:   +80 MB = 490 MB
+ Visualization:          +15 MB = 505 MB < 512 MB âœ…
```

**Äiá»u kiá»‡n:**
- Model < 200MB (cá»±c ká»³ aggressive quantization!)
- TensorFlow tá»‘i Æ°u tá»‘i Ä‘a
- Minimal Django setup

**Kháº£ thi khÃ´ng?** âš ï¸ KHÃ“! Model dermatology thÆ°á»ng > 200MB

---

### Option 2: Táº¯t TensorFlow eager execution

```python
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
```

**Tiáº¿t kiá»‡m:** ~50-100MB runtime memory

```
Django + Python:          ~70 MB
TensorFlow (graph mode):  ~80 MB  (thay vÃ¬ 150MB)
Model:                   ~300 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IDLE:                    ~450 MB

+ Inference:              +20 MB = 470 MB
+ Grad-CAM:               +30 MB = 500 MB < 512 MB âœ… (vá»«a khÃ­t!)
```

**NhÆ°ng:** Grad-CAM code cáº§n rewrite Ä‘á»ƒ dÃ¹ng graph mode! Phá»©c táº¡p!

---

### Option 3: Compute Grad-CAM OFFLINE

**Ã tÆ°á»Ÿng:**
- Request 1: Inference only, return prediction
- Background job: Compute Grad-CAM sau
- Request 2: Fetch Grad-CAM result

**Pros:**
- Peak memory tháº¥p hÆ¡n (khÃ´ng inference + Grad-CAM cÃ¹ng lÃºc)

**Cons:**
- Phá»©c táº¡p (cáº§n queue system)
- User pháº£i chá» 2 requests
- PA Free khÃ´ng cÃ³ background workers!

---

## ğŸ“Š KIá»‚M TRA THá»°C Táº¾

### CÃ¡ch duy nháº¥t Ä‘á»ƒ biáº¿t cháº¯c:

```bash
# Deploy lÃªn PA
# Upload áº£nh
# Monitor memory

curl https://yourusername.pythonanywhere.com/memory-status

# Check trong error log
# Náº¿u tháº¥y "Killed" â†’ Over 512MB
```

### Test tá»«ng bÆ°á»›c:

**Test 1: Chá»‰ load model**
```bash
PRELOAD_MODEL=true
ENABLE_GRADCAM=false
```
â†’ Xem idle memory lÃ  bao nhiÃªu

**Test 2: Inference khÃ´ng Grad-CAM**
```bash
PRELOAD_MODEL=false  # Lazy load
ENABLE_GRADCAM=false
```
â†’ Upload áº£nh, xem peak memory

**Test 3: Inference + Grad-CAM**
```bash
PRELOAD_MODEL=false
ENABLE_GRADCAM=true
```
â†’ Upload áº£nh, xem cÃ³ bá»‹ kill khÃ´ng

---

## ğŸ¯ THá»°C Táº¾ PHÅ©NG

### âŒ Kháº£ nÄƒng cao: KHÃ”NG THá»‚ báº­t Grad-CAM trÃªn 512MB

LÃ½ do:
- Model dermatology thÆ°á»ng > 300MB
- TensorFlow runtime: ~120-150MB
- Django: ~70-80MB
- **Total idle: ~490-530MB** (Ä‘Ã£ sÃ¡t limit!)
- Inference + Grad-CAM: +50-100MB
- **Peak: 540-630MB > 512MB** âŒ

### âœ… Giáº£i phÃ¡p thá»±c táº¿:

**Option A: Táº®T Grad-CAM (PA Free)**
```bash
PRELOAD_MODEL=false
ENABLE_GRADCAM=false
```

**Option B: Upgrade PA Hacker ($5/month, 1GB RAM)**
```bash
PRELOAD_MODEL=false
ENABLE_GRADCAM=true   # âœ… 1GB Ä‘á»§ cho cáº£ model + Grad-CAM!
```

**Option C: DÃ¹ng Render vá»›i pre-loading**
```bash
PRELOAD_MODEL=true
ENABLE_GRADCAM=true
```
(Render cÃ³ váº» flexible hÆ¡n vá» RAM limit)

---

## ğŸ™ XIN Lá»–I!

TÃ´i Ä‘Ã£ quÃ¡ láº¡c quan vÃ  tÃ­nh toÃ¡n sai vá»:

1. âŒ "Linux tolerate temporary spike" â†’ **SAI!** Hard limit lÃ  hard limit!
2. âŒ "Peak 780MB chá»‰ 2-3s" â†’ **KHÃ”NG QUAN TRá»ŒNG!** VÆ°á»£t 512MB = kill!
3. âŒ "Memory overcommit giÃºp Ä‘Æ°á»£c" â†’ **CHá»ˆ giÃºp vá»›i virtual memory, khÃ´ng pháº£i hard limit!**

### Sá»± tháº­t:

**PythonAnywhere Free 512MB:**
- âœ… Chá»‰ inference (khÃ´ng Grad-CAM): CÃ“ THá»‚ (náº¿u model < 300MB)
- âŒ Inference + Grad-CAM: KHÃ”NG THá»‚ (peak > 512MB)

**Náº¿u muá»‘n Grad-CAM trÃªn PA:**
- Pháº£i upgrade plan ($5/month â†’ 1GB RAM)
- Hoáº·c model cá»±c ká»³ nhá» (<200MB) - khÃ³!

---

## ğŸ“ RECOMMENDATION THá»°C Táº¾

### PythonAnywhere Free (512MB):

```bash
# .env - REALISTIC CONFIG
PRELOAD_MODEL=false
ENABLE_GRADCAM=false      # âŒ Táº®T Ä‘á»ƒ trÃ¡nh OOM

# Quantize model Ä‘á»ƒ fit inference
# Model pháº£i < 300MB
```

**LÃ½ do:**
- 512MB lÃ  HARD LIMIT
- Model + TensorFlow + Django + Inference = ~510-530MB
- ThÃªm Grad-CAM = OVER 512MB â†’ KILL!

### PythonAnywhere Hacker ($5/month, 1GB):

```bash
# .env - OPTIMAL CONFIG
PRELOAD_MODEL=false
ENABLE_GRADCAM=true       # âœ… Báº¬T! 1GB Ä‘á»§

# Model cÃ³ thá»ƒ lá»›n hÆ¡n (< 600MB)
```

### Render Free (512MB):

```bash
# .env
PRELOAD_MODEL=true        # âœ… Pháº£i pre-load
ENABLE_GRADCAM=true       # âœ… CÃ³ thá»ƒ báº­t (náº¿u model < 300MB)

# Render cÃ³ váº» linh hoáº¡t hÆ¡n vá» memory
# NhÆ°ng pháº£i pre-load Ä‘á»ƒ trÃ¡nh timeout
```

---

## ğŸ¯ Káº¾T LUáº¬N ÄÃšNG

**User há»i Ä‘Ãºng!** "TÆ°á»Ÿng luÃ´n dÆ°á»›i 512MB mÃ ?"

â†’ ÄÃºng rá»“i, PHáº¢I LUÃ”N < 512MB! 

â†’ Náº¿u peak > 512MB â†’ App bá»‹ kill!

â†’ Vá»›i model dermatology + Grad-CAM â†’ KhÃ³ giá»¯ < 512MB!

â†’ **Pháº£i táº¯t Grad-CAM HOáº¶C upgrade plan!**

**Xin lá»—i vÃ¬ tÃ­nh toÃ¡n sai!** ğŸ™
