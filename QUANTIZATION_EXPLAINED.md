# ğŸ”¢ Model Quantization - Giáº£i ThÃ­ch Cá»°C Ká»² Dá»… Hiá»ƒu

## ğŸ¯ Quantization lÃ  gÃ¬?

**Má»™t cÃ¢u:** Giáº£m Ä‘á»™ chÃ­nh xÃ¡c cá»§a sá»‘ Ä‘á»ƒ tiáº¿t kiá»‡m dung lÆ°á»£ng!

---

## ğŸ’¡ VÃ­ dá»¥ Thá»±c Táº¿ #1: Äo Chiá»u Cao

### Scenario: Äo chiá»u cao ngÆ°á»i

**CÃ¡ch 1: SiÃªu chÃ­nh xÃ¡c (float32 - Normal model)**
```
Báº¡n: 1.724583921 mÃ©t
Máº¹:  1.638274652 mÃ©t  
Bá»‘:  1.759283746 mÃ©t
```
- ChÃ­nh xÃ¡c tá»›i **9 chá»¯ sá»‘ tháº­p phÃ¢n**!
- Tá»‘n nhiá»u giáº¥y Ä‘á»ƒ ghi (4 bytes má»—i sá»‘)

**CÃ¡ch 2: Äá»§ chÃ­nh xÃ¡c (float16 - Quantized model)**
```
Báº¡n: 1.72 mÃ©t
Máº¹:  1.64 mÃ©t
Bá»‘:  1.76 mÃ©t
```
- ChÃ­nh xÃ¡c tá»›i **2 chá»¯ sá»‘ tháº­p phÃ¢n**
- Tá»‘n Ã­t giáº¥y hÆ¡n (2 bytes má»—i sá»‘)

**CÃ¢u há»i:** CÃ³ cáº§n chÃ­nh xÃ¡c tá»›i 9 chá»¯ sá»‘ khÃ´ng?

**Tráº£ lá»i:** KHÃ”NG! 2 chá»¯ sá»‘ Ä‘Ã£ Äá»¦!
- Sai sá»‘: 0.004 mÃ©t = 4mm
- KhÃ´ng ai quan tÃ¢m 4mm khi Ä‘o chiá»u cao!

---

## ğŸ–¼ï¸ VÃ­ dá»¥ Thá»±c Táº¿ #2: áº¢nh

### Scenario: LÆ°u mÃ u sáº¯c pixel

**RGB Color - Normal (float32):**
```
Red:   0.847592837465
Green: 0.293847562938  
Blue:  0.582749283746

â†’ Má»—i mÃ u: 4 bytes
â†’ 1 pixel: 12 bytes
â†’ áº¢nh 1000x1000: 12MB
```

**RGB Color - Quantized (float16):**
```
Red:   0.85
Green: 0.29
Blue:  0.58

â†’ Má»—i mÃ u: 2 bytes
â†’ 1 pixel: 6 bytes
â†’ áº¢nh 1000x1000: 6MB (tiáº¿t kiá»‡m 50%!)
```

**Máº¯t ngÆ°á»i cÃ³ tháº¥y khÃ¡c biá»‡t?** 

**KHÃ”NG!** 0.85 vs 0.847592... â†’ Máº¯t ngÆ°á»i khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c!

---

## ğŸ¤– Ãp Dá»¥ng VÃ o AI Model

### Model = HÃ ng Triá»‡u Sá»‘!

```
EfficientNetV2S model cÃ³:
- 20 triá»‡u parameters (weights)
- Má»—i weight = 1 sá»‘ thá»±c

Normal model (float32):
20,000,000 weights Ã— 4 bytes = 80MB

Quantized model (float16):
20,000,000 weights Ã— 2 bytes = 40MB

TIáº¾T KIá»†M: 50%! (40MB)
```

---

## ğŸ“Š Float32 vs Float16

### Float32 (4 bytes = 32 bits):

```
VÃ­ dá»¥ sá»‘: 3.14159265358979323846...

LÆ°u Ä‘Æ°á»£c: 
- Äá»™ chÃ­nh xÃ¡c: ~7-8 chá»¯ sá»‘ tháº­p phÃ¢n
- Range: Â±3.4 Ã— 10^38
- Size: 4 bytes

Example:
3.14159265 â† ChÃ­nh xÃ¡c tá»›i 9 chá»¯ sá»‘
```

### Float16 (2 bytes = 16 bits):

```
VÃ­ dá»¥ sá»‘: 3.14159265358979323846...

LÆ°u Ä‘Æ°á»£c:
- Äá»™ chÃ­nh xÃ¡c: ~3-4 chá»¯ sá»‘ tháº­p phÃ¢n  
- Range: Â±65504
- Size: 2 bytes

Example:
3.142 â† ChÃ­nh xÃ¡c tá»›i 4 chá»¯ sá»‘

Sai sá»‘: 0.00040735... â† Ráº¤T NHá»!
```

---

## ğŸ¯ Táº¡i Sao Quantization Váº«n OK?

### Deep Learning khÃ´ng cáº§n siÃªu chÃ­nh xÃ¡c!

**LÃ½ do:**

1. **Model há»c patterns, khÃ´ng pháº£i sá»‘ chÃ­nh xÃ¡c**
   ```
   Model há»c: "Náº¿u cÃ³ Ä‘á»‘m Ä‘á», nhá»t â†’ Má»¥n"
   KhÃ´ng pháº£i: "Náº¿u pixel[0,0] = 0.847592837 â†’ Má»¥n"
   
   â†’ Weight = 0.85 hay 0.847592 â†’ Káº¿t quáº£ giá»‘ng nhau!
   ```

2. **Sai sá»‘ nhá» hÆ¡n nhiá»…u tá»± nhiÃªn**
   ```
   Äá»™ sÃ¡ng áº£nh: Â±5%
   GÃ³c chá»¥p khÃ¡c: Â±10%
   Camera khÃ¡c: Â±15%
   
   Quantization error: Â±0.01% â† KHÃ”NG ÄÃNG Ká»‚!
   ```

3. **Robustness**
   ```
   Model tá»‘t = Robust vá»›i noise
   Quantization = ThÃªm 1 chÃºt noise
   â†’ Model váº«n hoáº¡t Ä‘á»™ng tá»‘t!
   ```

---

## ğŸ”¬ So SÃ¡nh Cá»¥ Thá»ƒ

### VÃ­ dá»¥: Weight trong model

**Weight gá»‘c (float32):**
```python
weight = 0.847592837465
```

**Weight sau quantize (float16):**
```python
weight_quantized = 0.8476
```

**Sai sá»‘:**
```python
error = |0.847592837465 - 0.8476|
      = 0.000007162535
      = 0.0008% â† Cá»°C NHá»!
```

**Impact lÃªn prediction:**
```python
# Giáº£ sá»­ input = 100
output_original  = 100 Ã— 0.847592837465 = 84.7592837465
output_quantized = 100 Ã— 0.8476         = 84.76

difference = 0.0007 â† KhÃ´ng Ä‘Ã¡ng ká»ƒ!
```

---

## ğŸ“‰ Impact LÃªn Accuracy

### Thá»±c nghiá»‡m vá»›i cÃ¡c model lá»›n:

```
ImageNet Classification:
â”œâ”€ ResNet50 (float32):     76.1% accuracy
â”œâ”€ ResNet50 (float16):     76.0% accuracy
â””â”€ Loss:                   0.1% â† Háº§u nhÆ° khÃ´ng Ä‘á»•i!

EfficientNetV2:
â”œâ”€ Normal (float32):       85.3% accuracy
â”œâ”€ Quantized (float16):    85.1% accuracy
â””â”€ Loss:                   0.2% â† Cháº¥p nháº­n Ä‘Æ°á»£c!

Skin Disease Model (Æ°á»›c tÃ­nh):
â”œâ”€ Normal:                 ~92% accuracy
â”œâ”€ Quantized:              ~91% accuracy
â””â”€ Loss:                   ~1% â† Váº«n ráº¥t tá»‘t!
```

**Káº¿t luáº­n:** Máº¥t ~0.2-1% accuracy, khÃ´ng Ä‘Ã¡ng ká»ƒ!

---

## ğŸ’¾ Quantization Script Hoáº¡t Äá»™ng NhÆ° Tháº¿ NÃ o?

### Code trong `quantize_model.py`:

```python
# 1. Load model gá»‘c
model = keras.models.load_model("dermatology_stage1.keras")
print(f"Original size: {os.path.getsize(path)} bytes")

# 2. Convert weights to float16
for layer in model.layers:
    if hasattr(layer, 'kernel'):  # Layer cÃ³ weights
        # Convert kernel (weights) tá»« float32 â†’ float16
        layer.kernel = tf.cast(layer.kernel, tf.float16)
    
    if hasattr(layer, 'bias'):  # Layer cÃ³ bias
        # Convert bias tá»« float32 â†’ float16
        layer.bias = tf.cast(layer.bias, tf.float16)

# 3. Save model má»›i
model.save("dermatology_stage1_fp16.keras")
print(f"Quantized size: {os.path.getsize(path)} bytes")
```

**Giá»‘ng nhÆ°:**
```python
# TrÆ°á»›c:
height = 1.724583921  # float32, 4 bytes

# Sau quantize:
height = 1.72         # float16, 2 bytes

# Váº«n lÆ°u cÃ¹ng info (chiá»u cao)
# Chá»‰ khÃ¡c: Ã­t chá»¯ sá»‘ tháº­p phÃ¢n hÆ¡n
```

---

## ğŸ¬ QuÃ¡ TrÃ¬nh Quantization

### Step-by-step:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORIGINAL MODEL (float32)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1:                                 â”‚
â”‚   weight[0] = 0.847592837465 (4 bytes)  â”‚
â”‚   weight[1] = 0.293847562938 (4 bytes)  â”‚
â”‚   ...                                    â”‚
â”‚   20M weights Ã— 4 bytes = 80MB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
        QUANTIZATION
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUANTIZED MODEL (float16)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1:                                 â”‚
â”‚   weight[0] = 0.8476 (2 bytes)          â”‚
â”‚   weight[1] = 0.2938 (2 bytes)          â”‚
â”‚   ...                                    â”‚
â”‚   20M weights Ã— 2 bytes = 40MB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FILE SIZE: 80MB â†’ 40MB (50% smaller!)
RAM USAGE: 225MB â†’ 120MB (47% smaller!)
```

---

## ğŸ” CÃ³ Máº¥t GÃ¬ KhÃ´ng?

### âœ… KhÃ´ng Ä‘á»•i:

```
âœ… Model architecture (cáº¥u trÃºc) - Giá»‘ng há»‡t
âœ… Number of layers - Giá»‘ng há»‡t
âœ… Layer connections - Giá»‘ng há»‡t
âœ… Input/output format - Giá»‘ng há»‡t
âœ… Trained patterns - Giá»‘ng há»‡t
```

### âš ï¸ Thay Ä‘á»•i:

```
âš ï¸ Weight precision: float32 â†’ float16
âš ï¸ Computation precision: CÃ³ thá»ƒ Ã­t chÃ­nh xÃ¡c hÆ¡n 1 chÃºt
âš ï¸ Accuracy: Giáº£m ~0.2-1%
```

### âŒ Trade-offs:

```
âœ… File size: -50%
âœ… RAM usage: -47%
âœ… Speed: TÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c nhanh hÆ¡n
âš ï¸ Accuracy: -0.2~1%
```

---

## ğŸ§ª LÃ m Sao Biáº¿t Quantization OK?

### Test trÆ°á»›c khi deploy:

```bash
# 1. Quantize model
python Dermal/quantize_model.py

# 2. Test vá»›i áº£nh máº«u
python test_quantized_model.py

Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Original Model:                         â”‚
â”‚ - Acne: 95.3%                          â”‚
â”‚ - Eczema: 2.1%                         â”‚
â”‚ - Healthy: 1.2%                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Quantized Model:                        â”‚
â”‚ - Acne: 94.8%  (â†“0.5%)                â”‚
â”‚ - Eczema: 2.3% (â†‘0.2%)                â”‚
â”‚ - Healthy: 1.4% (â†‘0.2%)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Difference: <1% âœ… OK!                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Náº¿u:**
- Difference < 1% â†’ âœ… VERY GOOD!
- Difference 1-2% â†’ âœ… OK, acceptable
- Difference > 3% â†’ âš ï¸ May need to reconsider

---

## ğŸ’¡ VÃ­ Dá»¥ Tá»•ng Há»£p - Báº£n Äá»“

### Scenario: Báº£n Ä‘á»“ Google Maps

**CÃ¡ch 1: SiÃªu chi tiáº¿t (float32)**
```
Tá»a Ä‘á»™ nhÃ  báº¡n:
Latitude:  10.762622847593827465
Longitude: 106.682938475629384756

â†’ ChÃ­nh xÃ¡c tá»›i milimeter!
â†’ File map: 500MB
```

**CÃ¡ch 2: Äá»§ chi tiáº¿t (float16)**
```
Tá»a Ä‘á»™ nhÃ  báº¡n:
Latitude:  10.7626
Longitude: 106.6829

â†’ ChÃ­nh xÃ¡c tá»›i vÃ i mÃ©t
â†’ File map: 250MB
```

**CÃ¢u há»i:** CÃ³ cáº§n chÃ­nh xÃ¡c tá»›i milimeter khÃ´ng?

**Tráº£ lá»i:** KHÃ”NG!
- Sai sá»‘ vÃ i mÃ©t â†’ Váº«n tÃ¬m Ä‘Æ°á»£c nhÃ !
- File nháº¹ hÆ¡n 50% â†’ Download nhanh hÆ¡n!
- RAM Ã­t hÆ¡n â†’ Äiá»‡n thoáº¡i khÃ´ng lag!

**Ãp dá»¥ng vÃ o AI model:**
- Sai sá»‘ nhá» â†’ Váº«n cháº©n Ä‘oÃ¡n Ä‘Ãºng!
- RAM Ã­t hÆ¡n â†’ App khÃ´ng crash!
- File nhá» hÆ¡n â†’ Deploy nhanh hÆ¡n!

---

## ğŸ¯ Khi NÃ o NÃŠN Quantize?

### âœ… NÃŠN quantize khi:

```
âœ… RAM háº¡n cháº¿ (nhÆ° Render 512MB)
âœ… Disk space háº¡n cháº¿
âœ… Inference only (khÃ´ng train)
âœ… Accuracy drop < 2% lÃ  OK
âœ… Cáº§n deploy nhanh
```

### âŒ KHÃ”NG NÃŠN quantize khi:

```
âŒ Cáº§n accuracy tuyá»‡t Ä‘á»‘i cao nháº¥t
âŒ RAM dÆ° thá»«a (>2GB)
âŒ Research/training (Ä‘ang train model)
âŒ Medical diagnosis cá»±c ká»³ quan trá»ng
   (tuy nhiÃªn 1% drop thÆ°á»ng váº«n acceptable)
```

---

## ğŸ“Š Quantization Levels

### CÃ¡c má»©c Ä‘á»™ quantization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ float32 (Original)                        â”‚
â”‚ - Size: 100%                              â”‚
â”‚ - Accuracy: 100%                          â”‚
â”‚ - Default for training                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ float16 (Half precision) â† TA DÃ™NG CÃI NÃ€Yâ”‚
â”‚ - Size: 50%                               â”‚
â”‚ - Accuracy: 98-99%                        â”‚
â”‚ - Good balance                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ int8 (8-bit quantization)                 â”‚
â”‚ - Size: 25%                               â”‚
â”‚ - Accuracy: 95-98%                        â”‚
â”‚ - More aggressive                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ int4 (4-bit quantization)                 â”‚
â”‚ - Size: 12.5%                             â”‚
â”‚ - Accuracy: 90-95%                        â”‚
â”‚ - Very aggressive, may lose quality      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ChÃºng ta dÃ¹ng float16:**
- Balance tá»‘t giá»¯a size vÃ  accuracy
- Dá»… implement
- Minimal accuracy loss

---

## âœ… TÃ³m Láº¡i Cá»°C NGáº®N

### Quantization lÃ  gÃ¬?

**= Giáº£m Ä‘á»™ chÃ­nh xÃ¡c cá»§a sá»‘ Ä‘á»ƒ tiáº¿t kiá»‡m dung lÆ°á»£ng**

### VÃ­ dá»¥:
```
Chiá»u cao: 1.724583921m â†’ 1.72m
Sai sá»‘: 0.004m = 4mm
CÃ³ quan trá»ng? KHÃ”NG!
```

### Ãp dá»¥ng AI:
```
20 triá»‡u weights Ã— giáº£m 50% precision
= File nhá» 50%
= RAM Ã­t 50%
= Accuracy giáº£m ~1%

Trade-off: ÄÃng giÃ¡!
```

### Script lÃ m gÃ¬?
```python
for weight in model:
    weight = float32_to_float16(weight)
# Má»—i weight tá»« 4 bytes â†’ 2 bytes
```

### Káº¿t quáº£:
```
Model: 95MB â†’ 48MB
RAM:   225MB â†’ 120MB
Accuracy: 92% â†’ 91% (â†“1%)

Worth it? âœ… YES!
```

---

## ğŸ¯ Decision Matrix

```
CÃ³ nÃªn quantize khÃ´ng?

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAM < 512MB, cáº§n Grad-CAM           â”‚
â”‚ â†’ âœ… YES! Quantize ngay!            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RAM 512MB-1GB, features nhiá»u       â”‚
â”‚ â†’ âœ… Consider quantize              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RAM > 2GB, khÃ´ng lo vá» memory       â”‚
â”‚ â†’ âŒ No need to quantize            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Vá»›i Render 512MB + Grad-CAM:
â†’ âœ… HIGHLY RECOMMENDED! â­â­â­
```

---

**Bottom Line:**

**Quantization = LÃ m trÃ²n sá»‘ Ä‘á»ƒ tiáº¿t kiá»‡m dung lÆ°á»£ng!**

Giá»‘ng nhÆ°:
- Äo chiá»u cao: 1.724583921m â†’ 1.72m
- Äá»§ chÃ­nh xÃ¡c, tiáº¿t kiá»‡m giáº¥y!

Káº¿t quáº£:
- âœ… Model nháº¹ hÆ¡n 50%
- âœ… RAM Ã­t hÆ¡n 50%  
- âš ï¸ Accuracy giáº£m ~1% (cháº¥p nháº­n Ä‘Æ°á»£c!)

**â†’ ÄÃng giÃ¡ cho Render 512MB! ğŸ¯**
