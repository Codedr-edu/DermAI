# ğŸ” PHÃ‚N TÃCH: PythonAnywhere vs Render

## ğŸ“Š SO SÃNH

| Feature | Render Free | PythonAnywhere Free |
|---------|-------------|---------------------|
| **RAM** | 512MB | 512MB âœ… Giá»‘ng nhau |
| **Timeout** | 30-60s | 300s (5 phÃºt) âœ… Tá»T HÆ N! |
| **Spin Down** | âœ… Yes (15 phÃºt khÃ´ng hoáº¡t Ä‘á»™ng) | âŒ NO (luÃ´n cháº¡y 24/7) |
| **WSGI Server** | Gunicorn (tá»± cáº¥u hÃ¬nh) | mod_wsgi hoáº·c uWSGI (cáº¥u hÃ¬nh sáºµn) |
| **Workers** | Tá»± config (1-N workers) | 1 worker (fixed) |
| **Deployment** | Git push (auto deploy) | Manual upload + reload |

---

## ğŸ¯ ÄIá»‚M KHÃC BIá»†T QUAN TRá»ŒNG

### 1. âš ï¸ KHÃ”NG CÃ“ "SPIN DOWN" ISSUE

**Render Free:**
```
App khÃ´ng hoáº¡t Ä‘á»™ng 15 phÃºt â†’ Spin down
â†“
User truy cáº­p â†’ Cold start (50s) + Load model (60s) = 110s
â†’ TIMEOUT náº¿u khÃ´ng pre-load model âŒ
```

**PythonAnywhere Free:**
```
App luÃ´n cháº¡y 24/7 (khÃ´ng sleep)
â†“
User truy cáº­p â†’ Chá»‰ cáº§n inference (5s)
â†’ KHÃ”NG Bá»Š TIMEOUT ngay cáº£ khi lazy load âœ…
```

**â¡ï¸ Váº¥n Ä‘á» timeout KHÃ”NG Tá»’N Táº I trÃªn PythonAnywhere!**

### 2. âš ï¸ WSGI SERVER KHÃC NHAU

**Render:**
- DÃ¹ng Gunicorn (báº¡n control má»i thá»©)
- Config: `--preload-app`, `--workers`, etc.
- Fork model: Master â†’ Workers

**PythonAnywhere:**
- DÃ¹ng **mod_wsgi** (Apache module) hoáº·c **uWSGI**
- **KHÃ”NG DÃ™NG Gunicorn!**
- Config qua Web UI, khÃ´ng pháº£i command line
- CÃ³ thá»ƒ dÃ¹ng "lazy loading" hoáº·c "daemon mode"

### 3. âš ï¸ RELOAD BEHAVIOR

**Render (Gunicorn):**
```python
# Vá»›i --preload-app:
Master process starts
  â†’ Django setup
  â†’ apps.py ready() Ä‘Æ°á»£c gá»i â† LOAD MODEL á» ÄÃ‚Y
  â†’ Fork workers
```

**PythonAnywhere (mod_wsgi):**
```python
# Daemon mode (máº·c Ä‘á»‹nh):
Worker process starts (khi cÃ³ request Ä‘áº§u tiÃªn)
  â†’ Django setup
  â†’ apps.py ready() Ä‘Æ°á»£c gá»i â† LOAD MODEL á» ÄÃ‚Y
  â†’ Handle request

# Hoáº·c embedded mode:
Apache starts
  â†’ Django setup trong Apache process
  â†’ apps.py ready() Ä‘Æ°á»£c gá»i
```

**â¡ï¸ ready() VáºªN HOáº T Äá»˜NG trÃªn PythonAnywhere!** âœ…

### 4. âš ï¸ RELOAD WEB APP

**PythonAnywhere:**
- Khi click "Reload" button trÃªn Web UI:
  - Kill worker processes
  - Start láº¡i Django
  - `ready()` Ä‘Æ°á»£c gá»i láº¡i
  - **Model pháº£i load láº¡i (60s)**

**Render:**
- Má»—i láº§n deploy:
  - Kill container
  - Build láº¡i
  - Start server má»›i
  - `ready()` Ä‘Æ°á»£c gá»i

---

## ğŸ¤” CODE HIá»†N Táº I CÃ“ HOáº T Äá»˜NG TRÃŠN PYTHONANYWHERE KHÃ”NG?

### âœ… NHá»®NG GÃŒ HOáº T Äá»˜NG Tá»T:

1. **`apps.py ready()` method** âœ…
   - Django standard, hoáº¡t Ä‘á»™ng trÃªn má»i platform
   - PythonAnywhere support Ä‘áº§y Ä‘á»§

2. **Environment variables** âœ…
   - Set Ä‘Æ°á»£c trong Web UI
   - `os.getenv()` hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

3. **Model pre-loading logic** âœ…
   - TensorFlow load bÃ¬nh thÆ°á»ng
   - Thread lock hoáº¡t Ä‘á»™ng
   - Memory management OK

### âš ï¸ NHá»®NG GÃŒ Cáº¦N KIá»‚M TRA:

#### 1. Detection Logic cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng?

Code hiá»‡n táº¡i:
```python
# Method 1: Check argv[0]
if 'gunicorn' in sys.argv[0].lower():  # â† KHÃ”NG CÃ“ "gunicorn" trÃªn PA!
    is_server = True

# Method 2: Check argv
if 'runserver' in sys.argv:  # â† KHÃ”NG CÃ“ "runserver" trÃªn PA!
    is_server = True

# Method 3: Check env (Tá»T!)
if os.getenv('DJANGO_SERVER_MODE') == 'true':  # â† HOáº T Äá»˜NG âœ…
    is_server = True

# Method 4: Check WSGI
if os.getenv('WSGI_APPLICATION'):  # â† CÃ“ THá»‚ HOáº T Äá»˜NG
    is_server = True
```

**TrÃªn PythonAnywhere:**
- `sys.argv[0]` cÃ³ thá»ƒ lÃ : `"python"`, `"uwsgi"`, hoáº·c mod_wsgi path
- `WSGI_APPLICATION` - CÃ³ thá»ƒ cÃ³, cÃ³ thá»ƒ khÃ´ng (tÃ¹y config)

**â¡ï¸ Method 3 (env var) lÃ  RELIABLE NHáº¤T!** âœ…

#### 2. Memory Usage

**PythonAnywhere Free:**
- 512MB RAM hard limit
- Náº¿u vÆ°á»£t quÃ¡ â†’ Worker bá»‹ kill
- Model ~1GB â†’ **CHáº®C CHáº®N Bá»Š KILL!** âŒ

**TÃ­nh toÃ¡n:**
```
Django base:     ~100MB
TensorFlow:      ~200MB
Model loaded:    ~1000MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:           ~1300MB >>> 512MB âŒ
```

**â¡ï¸ Model QUÃ Lá»šN cho 512MB!** âŒ

#### 3. Timeout cÃ³ cÃ²n lÃ  váº¥n Ä‘á» khÃ´ng?

**PythonAnywhere: 300s timeout**

TÃ¬nh huá»‘ng xáº¥u nháº¥t (lazy loading):
```
Request arrives â†’ Load model (60s) â†’ Inference (5s) = 65s
```

65s < 300s â†’ **KHÃ”NG Bá»Š TIMEOUT!** âœ…

**â¡ï¸ Lazy loading HOÃ€N TOÃ€N OK trÃªn PythonAnywhere!**

---

## ğŸ¯ Káº¾T LUáº¬N

### âŒ Váº¤N Äá»€ CHÃNH: RAM, KHÃ”NG PHáº¢I TIMEOUT!

**Render:**
- Váº¥n Ä‘á»: Spin down â†’ Request Ä‘áº§u tiÃªn timeout
- Giáº£i phÃ¡p: Pre-load model âœ…

**PythonAnywhere:**
- Váº¥n Ä‘á»: Model quÃ¡ lá»›n (1GB) > RAM (512MB) âŒ
- Timeout 300s â†’ KhÃ´ng pháº£i váº¥n Ä‘á» âœ…
- Lazy loading hoÃ n toÃ n OK âœ…

### ğŸ’¡ CHIáº¾N LÆ¯á»¢C CHO PYTHONANYWHERE

#### Option 1: KHÃ”NG PRE-LOAD (RECOMMENDED)

**Táº¡i sao:**
- Timeout 300s â†’ Äá»§ thá»i gian load model
- KhÃ´ng spin down â†’ Request Ä‘áº§u tiÃªn khÃ´ng cháº­m hÆ¡n cÃ¡c request sau
- Tiáº¿t kiá»‡m RAM â†’ TÄƒng kháº£ nÄƒng app khÃ´ng bá»‹ kill

**Config:**
```bash
# TrÃªn PythonAnywhere Web UI, set env var:
PRELOAD_MODEL=false
```

**Káº¿t quáº£:**
- Model load khi cÃ³ request Ä‘áº§u tiÃªn (~60s)
- CÃ¡c request sau: nhanh (~5s)
- RAM usage: tÄƒng dáº§n (chá»‰ khi cáº§n)

#### Option 2: PRE-LOAD (NGUY HIá»‚M)

**Táº¡i sao:**
- Model load ngay khi app start
- RAM 1.3GB > 512MB â†’ **Bá»‹ kill ngay!** âŒ

**Chá»‰ dÃ¹ng náº¿u:**
- Model Ä‘Ã£ Ä‘Æ°á»£c quantize (< 400MB)
- Táº¯t Grad-CAM
- Upgrade lÃªn paid plan (> 512MB RAM)

---

## ğŸ”§ CODE Cáº¦N Sá»¬A

### Váº¥n Ä‘á»: Detection logic khÃ´ng hoáº¡t Ä‘á»™ng trÃªn PythonAnywhere

Code hiá»‡n táº¡i rely on `gunicorn` hoáº·c `runserver` â†’ KhÃ´ng detect Ä‘Æ°á»£c PA!

### Fix: Cáº£i thiá»‡n detection

```python
# apps.py
def ready(self):
    # ... existing checks ...
    
    # Only pre-load in actual server processes
    is_server = False
    
    # Method 1: Check argv[0] (works for Gunicorn)
    if sys.argv and len(sys.argv) > 0:
        argv0_lower = sys.argv[0].lower()
        if 'gunicorn' in argv0_lower or 'uvicorn' in argv0_lower or 'uwsgi' in argv0_lower:
            is_server = True
    
    # Method 2: Check sys.argv for runserver
    if 'runserver' in sys.argv:
        is_server = True
    
    # Method 3: Check environment variable (RELIABLE!)
    if os.getenv('DJANGO_SERVER_MODE') == 'true':
        is_server = True
    
    # Method 4: Check WSGI
    if os.getenv('WSGI_APPLICATION') or os.getenv('SERVER_SOFTWARE'):
        is_server = True
    
    # Method 5: Check if mod_wsgi (PythonAnywhere)
    # mod_wsgi sets this variable
    if 'mod_wsgi' in str(sys.modules.get('__main__', '')):
        is_server = True
    
    # Method 6: If wsgi.py is being imported (not manage.py)
    # PythonAnywhere loads via wsgi.py
    if 'wsgi' in sys.argv[0].lower():
        is_server = True
```

---

## ğŸ“‹ CHECKLIST CHO PYTHONANYWHERE

### TrÆ°á»›c khi deploy:

- [ ] Set `PRELOAD_MODEL=false` (RECOMMENDED cho 512MB RAM)
- [ ] Set `ENABLE_GRADCAM=false` (tiáº¿t kiá»‡m ~200MB)
- [ ] Set `DJANGO_SERVER_MODE=true` (náº¿u muá»‘n pre-load)
- [ ] Xem model size: `ls -lh Dermal/dermatology_stage1.keras`
- [ ] Náº¿u model > 400MB â†’ KHÃ”NG pre-load!

### Sau khi deploy:

- [ ] Check memory usage trÃªn PA dashboard
- [ ] Test upload áº£nh (request Ä‘áº§u tiÃªn cÃ³ thá»ƒ cháº­m, OK!)
- [ ] Náº¿u app bá»‹ kill â†’ Táº¯t pre-loading hoáº·c quantize model

---

## ğŸš¨ WARNING

**PYTHONANYWHERE FREE (512MB) + MODEL Lá»šN (1GB) = KHÃ”NG TÆ¯Æ NG THÃCH!**

**Giáº£i phÃ¡p:**
1. âœ… Táº¯t pre-loading: `PRELOAD_MODEL=false` (lazy load khi cáº§n)
2. âœ… Táº¯t Grad-CAM: `ENABLE_GRADCAM=false`
3. âœ… Quantize model xuá»‘ng < 400MB
4. âœ… Upgrade PythonAnywhere plan (Hacker: $5/month, 1GB RAM)

**PythonAnywhere cÃ³ lá»£i tháº¿:**
- Timeout 300s (5 phÃºt) vs Render 30-60s
- KhÃ´ng spin down â†’ Lazy loading hoÃ n toÃ n OK!
